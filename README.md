**Dataset**: MNIST

**Results**:

Swish:

    Epoch 1/10
    32s - loss: 0.2681 - acc: 0.9200 - val_loss: 0.0606 - val_acc: 0.9829
    Epoch 2/10
    30s - loss: 0.0761 - acc: 0.9812 - val_loss: 0.0438 - val_acc: 0.9888
    Epoch 3/10
    27s - loss: 0.0605 - acc: 0.9848 - val_loss: 0.0453 - val_acc: 0.9882
    Epoch 4/10
    28s - loss: 0.0479 - acc: 0.9883 - val_loss: 0.0338 - val_acc: 0.9910
    Epoch 5/10
    27s - loss: 0.0375 - acc: 0.9904 - val_loss: 0.0458 - val_acc: 0.9884
    Epoch 6/10
    27s - loss: 0.0347 - acc: 0.9907 - val_loss: 0.0540 - val_acc: 0.9884
    Epoch 7/10
    30s - loss: 0.0327 - acc: 0.9921 - val_loss: 0.0521 - val_acc: 0.9866
    Epoch 8/10
    28s - loss: 0.0284 - acc: 0.9931 - val_loss: 0.0455 - val_acc: 0.9902
    Epoch 9/10
    30s - loss: 0.0281 - acc: 0.9930 - val_loss: 0.0353 - val_acc: 0.9913
    Epoch 10/10
    30s - loss: 0.0263 - acc: 0.9932 - val_loss: 0.0531 - val_acc: 0.9908
    Running time: 303.83065724372864


LeakyRelu with alpha = 0.01

    Epoch 1/10
    30s - loss: 0.3333 - acc: 0.8967 - val_loss: 0.0410 - val_acc: 0.9867
    Epoch 2/10
    30s - loss: 0.0935 - acc: 0.9757 - val_loss: 0.0367 - val_acc: 0.9891
    Epoch 3/10
    26s - loss: 0.0666 - acc: 0.9833 - val_loss: 0.0398 - val_acc: 0.9898
    Epoch 4/10
    22s - loss: 0.0522 - acc: 0.9866 - val_loss: 0.0400 - val_acc: 0.9898
    Epoch 5/10
    23s - loss: 0.0465 - acc: 0.9883 - val_loss: 0.0447 - val_acc: 0.9897
    Epoch 6/10
    23s - loss: 0.0367 - acc: 0.9903 - val_loss: 0.0299 - val_acc: 0.9912
    Epoch 7/10
    22s - loss: 0.0361 - acc: 0.9908 - val_loss: 0.0320 - val_acc: 0.9917
    Epoch 8/10
    22s - loss: 0.0322 - acc: 0.9920 - val_loss: 0.0345 - val_acc: 0.9922
    Epoch 9/10
    22s - loss: 0.0296 - acc: 0.9920 - val_loss: 0.0325 - val_acc: 0.9927
    Epoch 10/10
    24s - loss: 0.0236 - acc: 0.9935 - val_loss: 0.0458 - val_acc: 0.9908
    Running time: 257.42275738716125


**Model architecture**:
_________________________________________________________________
Layer (type)                 Output Shape              Param #
_________________________________________________________________
conv2d_1 (Conv2D)            (None, 28, 28, 96)        960
_________________________________________________________________
activation_1 (Activation)    (None, 28, 28, 96)        0
_________________________________________________________________
max_pooling2d_1 (MaxPooling2 (None, 14, 14, 96)        0
_________________________________________________________________
conv2d_2 (Conv2D)            (None, 14, 14, 96)        83040
_________________________________________________________________
activation_2 (Activation)    (None, 14, 14, 96)        0
_________________________________________________________________
max_pooling2d_2 (MaxPooling2 (None, 7, 7, 96)          0
_________________________________________________________________
conv2d_3 (Conv2D)            (None, 7, 7, 96)          83040
_________________________________________________________________
activation_3 (Activation)    (None, 7, 7, 96)          0
_________________________________________________________________
max_pooling2d_3 (MaxPooling2 (None, 4, 4, 96)          0
_________________________________________________________________
conv2d_4 (Conv2D)            (None, 4, 4, 96)          36960
_________________________________________________________________
activation_4 (Activation)    (None, 4, 4, 96)          0
_________________________________________________________________
max_pooling2d_4 (MaxPooling2 (None, 2, 2, 96)          0
_________________________________________________________________
flatten_1 (Flatten)          (None, 384)               0
_________________________________________________________________
dense_1 (Dense)              (None, 32)                12320
_________________________________________________________________
activation_5 (Activation)    (None, 32)                0
_________________________________________________________________
dropout_1 (Dropout)          (None, 32)                0
_________________________________________________________________
dense_2 (Dense)              (None, 32)                1056
_________________________________________________________________
activation_6 (Activation)    (None, 32)                0
_________________________________________________________________
dropout_2 (Dropout)          (None, 32)                0
_________________________________________________________________
dense_3 (Dense)              (None, 10)                330
_________________________________________________________________
Total params: 217,706
Trainable params: 217,706
Non-trainable params: 0